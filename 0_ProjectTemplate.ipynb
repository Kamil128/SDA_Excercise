{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee2a7f7-317c-4adc-8b20-c3d04acd3063",
   "metadata": {},
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eeb97a-9bbf-47c8-be67-b55860ee1de3",
   "metadata": {},
   "source": [
    "Dobrą praktyktą jest zawrzeć kilka informacji na temat problemu, którym będziemy się zajmować. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a0168-57c9-4245-8a51-ca1ea2c25bd9",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8fab9-c951-474e-89b4-aa560ad4cb80",
   "metadata": {},
   "source": [
    "Wczytujemy datset. Najczęściej:\n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "\n",
    "data_set = pd.read_csv('/path/to/data.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d054a2-48f1-4d74-9588-80ede93db479",
   "metadata": {},
   "source": [
    "# Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613d08b-2d79-458c-b693-2b5ba5919925",
   "metadata": {},
   "source": [
    "Sprawdzamy jakość danych, uzgadniamy typy, wybieramy _featury_ w sposób **ekspercki**.\n",
    "\n",
    "np.:\n",
    "```Python\n",
    "data_set.info()\n",
    "data_set['column'] = data_set['column'].astype('category')\n",
    "\n",
    "data_set.describe()\n",
    "data_set.describe(include='category')\n",
    "\n",
    "data_set.isnull().sum()/df.shape[0] * 100\n",
    "df.drop([list_col_drop], axis=1, inplace=True)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2621916-e156-4e52-8bfc-a476ac2f2666",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed572618-c8b7-4879-b07d-d7bbb41cb9fd",
   "metadata": {},
   "source": [
    "\n",
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(data_set,\n",
    "                                   test_size=0.2, \n",
    "                                   random_state=42)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914277f-9849-4165-bbe6-c768d4045fcf",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b963a-24e9-45dd-aa13-47850c3512e2",
   "metadata": {},
   "source": [
    "Analizujemy dataset pod różnym kątem.\n",
    "\n",
    "Eksplorujemy dane. \n",
    "\n",
    "Sprawdzamy rokłady, współzależności, kolerację. \n",
    "\n",
    "Tu dajemy się ponieść duszy artysty! I detektywa.\n",
    "\n",
    "Zazwyczaj przydaje się:\n",
    "```Python\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "Ale zachęcam do używania znacznie lepszych narzędiz jak:\n",
    "- [plotly](https://plotly.com/)\n",
    "- [bokeh](https://bokeh.org/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2d912-5eba-4990-bc5b-b9c576aeacf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360bd14-b424-4a95-bdfb-2cb094e8f140",
   "metadata": {},
   "source": [
    "W tej części następuje pryzgotowanie danych bezpośrednio do trenowania. Tutaj uzupełniamy brakujące wartości, standaryzujemy, normalizujemy, dyskretyzujemy, enkodujemy itd. \n",
    "\n",
    "```Python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X_train = imputer_num.fit_transform(X_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "X_train = ohe.fit_transform(X_train)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ffbc6-d47b-4263-be28-dee2e96ac3f9",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d51fa1-abe1-4f9c-8286-98e417767a8c",
   "metadata": {},
   "source": [
    "Jest to część preprocessingu. \n",
    "\n",
    "Jeśli nasze dane tego wymagają i mogłoby to polepszyć wyniki naszego modelu warto zbudować nowe featury lub dokonać jakiś niestandardowych operacji. Przykładem może być np.: \n",
    "- wyciągnięcie dnia tygodnia z daty\n",
    "- wyciągnięcie płci z imienia\n",
    "- na podstawie ilości rodziców i rodzeństwa sprawdzić czy ktoś podróżuje sam (Titanic dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5451a0-7e50-477c-b056-6d494ba399dc",
   "metadata": {},
   "source": [
    "# Building Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e59fb1-ada0-4b9c-90f6-61f7c26d77a9",
   "metadata": {},
   "source": [
    "Wszystkie operacje dokonane na zbiorze treningowym muszą zostać w ten sam sposób przeniesione na zbiór testowy. Czyli każdy transformer _wytrenowany_ na zbiorze treningowym musi dokonać transformacji na zbiorze testowym. To oznacza, że jeśli np. brakujące wartości zostały uzupełnione średnią ze zbioru treningowego, to tą samą wartością uzupełnimy zbiór testowy! \n",
    "\n",
    "W tym celu, żeby nie powtarzać tych samych operacji warto zbudować pipeline. Dobrą praktyką jest skorzystanie z biblioteki scikit-learn i skorzystanie z dostępnego API. Zapewni to dużą elastyczność przy ewentualnych zmianach oraz pozwoli łatow używać wszystkich komponentów. \n",
    "\n",
    "```Python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('step_1', ...),\n",
    "        ('step_2', ...),\n",
    "        ('step_3', ...),\n",
    "    ]\n",
    ")\n",
    "\n",
    "```\n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "\n",
    "\n",
    "Warto pamiętać o _cutomowych funkcjach_ z sklearn, które pomogą obsłużyć niestandardowe operacja np. z feature engineeringu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272cb1e-29de-42f7-9d06-d0339d802d13",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e46e57-e2d7-49ec-92bc-da2b19f0d7fc",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18258c52-2e66-4856-b073-0194aaaa98ad",
   "metadata": {},
   "source": [
    "Po preprocessingu następuje eksploracja modeli. Sprawdzamy jak zachowują się dane poddane różnym estymatorą. Czy złożoność pozwoli na użycie. Wstępna analiza pozwoli wybrać kilku potencjalnych kandydatów, którzy najlepiej opisują zbiór.\n",
    "\n",
    "```Python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a5f0d-e442-4b81-85cd-c32dcddf7eb4",
   "metadata": {},
   "source": [
    "## Model Selection/Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0578d-eaec-4201-80b3-72939709fb36",
   "metadata": {},
   "source": [
    "Bo wybraniu potencjalnych kadydatów następuje proces dostrajania modelu czyli przeszukiwaniu przestrzeni hiperparametrów w celu uzyskania najlepszych wyników. Do tego celu najlepiej przydaje się metoda grid search.\n",
    "\n",
    "```Python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(model, model_param, verbose=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c6f45-089b-4376-bcf8-b7d87dc8b009",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4858c-d08e-4d2a-8731-6becdf6d15ed",
   "metadata": {},
   "source": [
    "Po wybraniu najlepszego modelu następuje ewaluacja na zbiorze testowym, czyli sprawdzamy czy model nie jest przetrenowany, spełnia założenia o dokładności itd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba4761-bda0-4dfb-a249-be8791c42da8",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
